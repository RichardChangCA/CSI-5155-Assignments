{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "data = arff.loadarff('seismic-bumps.arff')\n",
    "dataset = pd.DataFrame(data[0])\n",
    "datainfo = pd.DataFrame(data[1])\n",
    "# print(dataset)\n",
    "# print(datainfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  2584\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "dataset.iloc[:,0] = label_encoder.fit_transform(dataset.iloc[:,0])\n",
    "dataset.iloc[:,1] = label_encoder.fit_transform(dataset.iloc[:,1])\n",
    "dataset.iloc[:,2] = label_encoder.fit_transform(dataset.iloc[:,2])\n",
    "dataset.iloc[:,7] = label_encoder.fit_transform(dataset.iloc[:,7])\n",
    "dataset.iloc[:,-1] = label_encoder.fit_transform(dataset.iloc[:,-1])\n",
    "\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "y = dataset.iloc[:,-1]\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# print(y)\n",
    "print(\"dataset_size: \", y.size)\n",
    "# X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78764479 0.88030888 0.89189189 0.92664093 0.93410853 0.93410853\n",
      " 0.93410853 0.93023256 0.93023256 0.93410853]\n",
      "Accuracy: 0.91 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:  [[2335   79]\n",
      " [ 158   12]]\n",
      "precision:  0.13186813186813187\n",
      "recall: 0.07058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"confusion_matrix: \",confusion_matrix(y,y_pred))\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "print(\"precision: \",precision_score(y,y_pred))\n",
    "print(\"recall:\", recall_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  4828\n",
      "[0.69214876 0.70247934 0.74380165 0.85950413 0.86307054 0.86514523\n",
      " 0.82572614 0.80912863 0.81950207 0.84232365]\n",
      "Accuracy of Oversampling: 0.80 (+/- 0.12)\n",
      "confusion matrix of oversampling:  [[1720  694]\n",
      " [ 261 2153]]\n",
      "precision of oversampling:  0.7562346329469617\n",
      "recall of oversampling: 0.891880695940348\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler()\n",
    "# X_over, y_over = ros.fit_resample(X, y)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "ros = SMOTE()\n",
    "X_over, y_over = ros.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_over.size)\n",
    "\n",
    "scores_over = cross_val_score(clf, X_over, y_over, cv=10)\n",
    "\n",
    "print(scores_over)\n",
    "print(\"Accuracy of Oversampling: %0.2f (+/- %0.2f)\" % (scores_over.mean(), scores_over.std() * 2))\n",
    "\n",
    "y_pred_over = cross_val_predict(clf, X_over, y_over, cv=10)\n",
    "\n",
    "print(\"confusion matrix of oversampling: \",confusion_matrix(y_over,y_pred_over))\n",
    "\n",
    "print(\"precision of oversampling: \",precision_score(y_over,y_pred_over))\n",
    "print(\"recall of oversampling:\", recall_score(y_over,y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  340\n",
      "[0.44117647 0.35294118 0.47058824 0.47058824 0.58823529 0.70588235\n",
      " 0.58823529 0.85294118 0.55882353 0.58823529]\n",
      "Accuracy of Undersampling: 0.56 (+/- 0.27)\n",
      "confusion matrix of undersampling:  [[95 75]\n",
      " [74 96]]\n",
      "precision of undersampling:  0.5614035087719298\n",
      "recall of undersampling: 0.5647058823529412\n"
     ]
    }
   ],
   "source": [
    "#undersampling\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids()\n",
    "X_under, y_under = cc.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_under.size)\n",
    "\n",
    "scores_under = cross_val_score(clf, X_under, y_under, cv=10)\n",
    "\n",
    "print(scores_under)\n",
    "print(\"Accuracy of Undersampling: %0.2f (+/- %0.2f)\" % (scores_under.mean(), scores_under.std() * 2))\n",
    "\n",
    "y_pred_under = cross_val_predict(clf, X_under, y_under, cv=10)\n",
    "\n",
    "print(\"confusion matrix of undersampling: \",confusion_matrix(y_under,y_pred_under))\n",
    "\n",
    "print(\"precision of undersampling: \",precision_score(y_under,y_pred_under))\n",
    "print(\"recall of undersampling:\", recall_score(y_under,y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  3157\n",
      "[0.82649842 0.93690852 0.93037975 0.98417722 0.98734177 0.98412698\n",
      " 0.97460317 0.98412698 0.96507937 0.98412698]\n",
      "Accuracy of combining oversampling and undersampling: 0.96 (+/- 0.09)\n",
      "confusion matrix of combining oversampling and undersampling:  [[1287  128]\n",
      " [  12 1730]]\n",
      "precision of combining oversampling and undersampling:  0.9311087190527448\n",
      "recall of combining oversampling and undersampling: 0.9931113662456946\n"
     ]
    }
   ],
   "source": [
    "#combine oversampling and undersampling\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN()\n",
    "X_combine, y_combine = smote_enn.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_combine.size)\n",
    "\n",
    "scores_combine = cross_val_score(clf, X_combine, y_combine, cv=10)\n",
    "\n",
    "print(scores_combine)\n",
    "print(\"Accuracy of combining oversampling and undersampling: %0.2f (+/- %0.2f)\" % (scores_combine.mean(), scores_combine.std() * 2))\n",
    "\n",
    "y_pred_combine = cross_val_predict(clf, X_combine, y_combine, cv=10)\n",
    "\n",
    "print(\"confusion matrix of combining oversampling and undersampling: \",confusion_matrix(y_combine,y_pred_combine))\n",
    "\n",
    "print(\"precision of combining oversampling and undersampling: \",precision_score(y_combine,y_pred_combine))\n",
    "print(\"recall of combining oversampling and undersampling:\", recall_score(y_combine,y_pred_combine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 8\n",
      "[0.70347003 0.73817035 0.78481013 0.89556962 0.87025316 0.8952381\n",
      " 0.84126984 0.84761905 0.7968254  0.88253968]\n",
      "Accuracy of feature selection: 0.83 (+/- 0.13)\n",
      "confusion matrix of feature selection:  [[1037  378]\n",
      " [ 173 1569]]\n",
      "precision of feature selection:  0.8058551617873652\n",
      "recall of feature selection: 0.9006888633754305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf_fs = ExtraTreesClassifier(n_estimators=50)\n",
    "clf_fs = clf_fs.fit(X_combine, y_combine)\n",
    "model_fs = SelectFromModel(clf_fs, prefit=True)\n",
    "X_fs = model_fs.transform(X_combine)\n",
    "print(\"feature dimension:\", X_fs.shape[1])             \n",
    "\n",
    "y_fs = y_combine\n",
    "\n",
    "scores_fs = cross_val_score(clf, X_fs, y_fs, cv=10)\n",
    "\n",
    "print(scores_fs)\n",
    "print(\"Accuracy of feature selection: %0.2f (+/- %0.2f)\" % (scores_fs.mean(), scores_fs.std() * 2))\n",
    "\n",
    "y_pred_fs = cross_val_predict(clf, X_fs, y_fs, cv=10)\n",
    "\n",
    "print(\"confusion matrix of feature selection: \",confusion_matrix(y_fs,y_pred_fs))\n",
    "\n",
    "print(\"precision of feature selection: \",precision_score(y_fs,y_pred_fs))\n",
    "print(\"recall of feature selection:\", recall_score(y_fs,y_pred_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83596215 0.7318612  0.91139241 0.93037975 0.87974684 0.88571429\n",
      " 0.86984127 0.86984127 0.82857143 0.8984127 ]\n",
      "Accuracy of feature selection: 0.86 (+/- 0.11)\n",
      "confusion matrix of feature selection:  [[1095  320]\n",
      " [ 109 1633]]\n",
      "precision of feature selection:  0.8361495135688684\n",
      "recall of feature selection: 0.9374282433983927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(C=0.5, penalty=\"l1\", dual=False).fit(X_combine, y_combine)\n",
    "model_fs_2 = SelectFromModel(lsvc, prefit=True)\n",
    "X_fs_2 = model_fs_2.transform(X_combine)\n",
    "print(\"feature dimension:\", X_fs_2.shape[1])\n",
    "y_fs_2 = y_combine\n",
    "\n",
    "scores_fs_2 = cross_val_score(clf, X_fs_2, y_fs_2, cv=10)\n",
    "\n",
    "print(scores_fs_2)\n",
    "print(\"Accuracy of feature selection: %0.2f (+/- %0.2f)\" % (scores_fs_2.mean(), scores_fs_2.std() * 2))\n",
    "\n",
    "y_pred_fs_2 = cross_val_predict(clf, X_fs_2, y_fs_2, cv=10)\n",
    "\n",
    "print(\"confusion matrix of feature selection: \",confusion_matrix(y_fs_2,y_pred_fs_2))\n",
    "\n",
    "print(\"precision of feature selection: \",precision_score(y_fs_2,y_pred_fs_2))\n",
    "print(\"recall of feature selection:\", recall_score(y_fs_2,y_pred_fs_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
