{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "data = arff.loadarff('seismic-bumps.arff')\n",
    "dataset = pd.DataFrame(data[0])\n",
    "datainfo = pd.DataFrame(data[1])\n",
    "# print(dataset)\n",
    "# print(datainfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  2584\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "dataset.iloc[:,0] = label_encoder.fit_transform(dataset.iloc[:,0])\n",
    "dataset.iloc[:,1] = label_encoder.fit_transform(dataset.iloc[:,1])\n",
    "dataset.iloc[:,2] = label_encoder.fit_transform(dataset.iloc[:,2])\n",
    "dataset.iloc[:,7] = label_encoder.fit_transform(dataset.iloc[:,7])\n",
    "dataset.iloc[:,-1] = label_encoder.fit_transform(dataset.iloc[:,-1])\n",
    "\n",
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "y = dataset.iloc[:,-1]\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# print(y)\n",
    "print(\"dataset_size: \", y.size)\n",
    "# X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62162162 0.81467181 0.92664093 0.93436293 0.93410853 0.93410853\n",
      " 0.92635659 0.93410853 0.93410853 0.93410853]\n",
      "Accuracy: 0.89 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:  [[2264  150]\n",
      " [ 136   34]]\n",
      "precision:  0.18478260869565216\n",
      "recall: 0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"confusion_matrix: \",confusion_matrix(y,y_pred))\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "print(\"precision: \",precision_score(y,y_pred))\n",
    "print(\"recall:\", recall_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  4828\n",
      "[0.44214876 0.5661157  0.60950413 0.65082645 0.59543568 0.59958506\n",
      " 0.62863071 0.60373444 0.60995851 0.62240664]\n",
      "Accuracy of Oversampling: 0.59 (+/- 0.11)\n",
      "confusion matrix of oversampling:  [[1144 1270]\n",
      " [ 696 1718]]\n",
      "precision of oversampling:  0.5749665327978581\n",
      "recall of oversampling: 0.7116818558409279\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler()\n",
    "# X_over, y_over = ros.fit_resample(X, y)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "ros = SMOTE()\n",
    "X_over, y_over = ros.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_over.size)\n",
    "\n",
    "scores_over = cross_val_score(clf, X_over, y_over, cv=10)\n",
    "\n",
    "print(scores_over)\n",
    "print(\"Accuracy of Oversampling: %0.2f (+/- %0.2f)\" % (scores_over.mean(), scores_over.std() * 2))\n",
    "\n",
    "y_pred_over = cross_val_predict(clf, X_over, y_over, cv=10)\n",
    "\n",
    "print(\"confusion matrix of oversampling: \",confusion_matrix(y_over,y_pred_over))\n",
    "\n",
    "print(\"precision of oversampling: \",precision_score(y_over,y_pred_over))\n",
    "print(\"recall of oversampling:\", recall_score(y_over,y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  340\n",
      "[0.55882353 0.58823529 0.67647059 0.67647059 0.64705882 0.67647059\n",
      " 0.64705882 0.61764706 0.61764706 0.5       ]\n",
      "Accuracy of Undersampling: 0.62 (+/- 0.11)\n",
      "confusion matrix of undersampling:  [[ 64 106]\n",
      " [ 23 147]]\n",
      "precision of undersampling:  0.5810276679841897\n",
      "recall of undersampling: 0.8647058823529412\n"
     ]
    }
   ],
   "source": [
    "#undersampling\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids()\n",
    "X_under, y_under = cc.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_under.size)\n",
    "\n",
    "scores_under = cross_val_score(clf, X_under, y_under, cv=10)\n",
    "\n",
    "print(scores_under)\n",
    "print(\"Accuracy of Undersampling: %0.2f (+/- %0.2f)\" % (scores_under.mean(), scores_under.std() * 2))\n",
    "\n",
    "y_pred_under = cross_val_predict(clf, X_under, y_under, cv=10)\n",
    "\n",
    "print(\"confusion matrix of undersampling: \",confusion_matrix(y_under,y_pred_under))\n",
    "\n",
    "print(\"precision of undersampling: \",precision_score(y_under,y_pred_under))\n",
    "print(\"recall of undersampling:\", recall_score(y_under,y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  3201\n",
      "[0.5046729  0.67912773 0.80373832 0.8317757  0.734375   0.69375\n",
      " 0.7        0.70846395 0.67711599 0.73354232]\n",
      "Accuracy of combining oversampling and undersampling: 0.71 (+/- 0.17)\n",
      "confusion matrix of combining oversampling and undersampling:  [[1132  325]\n",
      " [ 614 1130]]\n",
      "precision of combining oversampling and undersampling:  0.7766323024054983\n",
      "recall of combining oversampling and undersampling: 0.6479357798165137\n"
     ]
    }
   ],
   "source": [
    "#combine oversampling and undersampling\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN()\n",
    "X_combine, y_combine = smote_enn.fit_resample(X, y)\n",
    "\n",
    "print(\"dataset_size: \", y_combine.size)\n",
    "\n",
    "scores_combine = cross_val_score(clf, X_combine, y_combine, cv=10)\n",
    "\n",
    "print(scores_combine)\n",
    "print(\"Accuracy of combining oversampling and undersampling: %0.2f (+/- %0.2f)\" % (scores_combine.mean(), scores_combine.std() * 2))\n",
    "\n",
    "y_pred_combine = cross_val_predict(clf, X_combine, y_combine, cv=10)\n",
    "\n",
    "print(\"confusion matrix of combining oversampling and undersampling: \",confusion_matrix(y_combine,y_pred_combine))\n",
    "\n",
    "print(\"precision of combining oversampling and undersampling: \",precision_score(y_combine,y_pred_combine))\n",
    "print(\"recall of combining oversampling and undersampling:\", recall_score(y_combine,y_pred_combine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 8\n",
      "[0.5046729  0.67601246 0.68224299 0.70716511 0.646875   0.665625\n",
      " 0.646875   0.64263323 0.62382445 0.68025078]\n",
      "Accuracy of feature selection: 0.65 (+/- 0.11)\n",
      "confusion matrix of feature selection:  [[1333  124]\n",
      " [1004  740]]\n",
      "precision of feature selection:  0.8564814814814815\n",
      "recall of feature selection: 0.4243119266055046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf_fs = ExtraTreesClassifier(n_estimators=50)\n",
    "clf_fs = clf_fs.fit(X_combine, y_combine)\n",
    "model_fs = SelectFromModel(clf_fs, prefit=True)\n",
    "X_fs = model_fs.transform(X_combine)\n",
    "print(\"feature dimension:\", X_fs.shape[1])             \n",
    "\n",
    "y_fs = y_combine\n",
    "\n",
    "scores_fs = cross_val_score(clf, X_fs, y_fs, cv=10)\n",
    "\n",
    "print(scores_fs)\n",
    "print(\"Accuracy of feature selection: %0.2f (+/- %0.2f)\" % (scores_fs.mean(), scores_fs.std() * 2))\n",
    "\n",
    "y_pred_fs = cross_val_predict(clf, X_fs, y_fs, cv=10)\n",
    "\n",
    "print(\"confusion matrix of feature selection: \",confusion_matrix(y_fs,y_pred_fs))\n",
    "\n",
    "print(\"precision of feature selection: \",precision_score(y_fs,y_pred_fs))\n",
    "print(\"recall of feature selection:\", recall_score(y_fs,y_pred_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 14\n",
      "[0.75077882 0.59813084 0.8411215  0.87227414 0.825      0.828125\n",
      " 0.85       0.82131661 0.78056426 0.84952978]\n",
      "Accuracy of feature selection: 0.80 (+/- 0.15)\n",
      "confusion matrix of feature selection:  [[1251  206]\n",
      " [ 429 1315]]\n",
      "precision of feature selection:  0.8645627876397107\n",
      "recall of feature selection: 0.7540137614678899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(C=0.5, penalty=\"l1\", dual=False).fit(X_combine, y_combine)\n",
    "model_fs_2 = SelectFromModel(lsvc, prefit=True)\n",
    "X_fs_2 = model_fs_2.transform(X_combine)\n",
    "print(\"feature dimension:\", X_fs_2.shape[1])\n",
    "y_fs_2 = y_combine\n",
    "\n",
    "scores_fs_2 = cross_val_score(clf, X_fs_2, y_fs_2, cv=10)\n",
    "\n",
    "print(scores_fs_2)\n",
    "print(\"Accuracy of feature selection: %0.2f (+/- %0.2f)\" % (scores_fs_2.mean(), scores_fs_2.std() * 2))\n",
    "\n",
    "y_pred_fs_2 = cross_val_predict(clf, X_fs_2, y_fs_2, cv=10)\n",
    "\n",
    "print(\"confusion matrix of feature selection: \",confusion_matrix(y_fs_2,y_pred_fs_2))\n",
    "\n",
    "print(\"precision of feature selection: \",precision_score(y_fs_2,y_pred_fs_2))\n",
    "print(\"recall of feature selection:\", recall_score(y_fs_2,y_pred_fs_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
